{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/transformers/blob/main/notebooks/mistral-half-A100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhhWHHlFDzeW"
      },
      "source": [
        "\n",
        "\n",
        "* https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
        "* https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1\n",
        "* https://towardsdatascience.com/mixtral-8x7b-understanding-and-running-the-sparse-mixture-of-experts-0e3fc7fde818\n",
        "* https://huggingface.co/chat/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYPmtLLXSJSb",
        "outputId": "ae64e200-4434-45c8-ab9c-ba99047ea138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 16 11:56:35 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              43W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tH2rsWWVF0yN"
      },
      "outputs": [],
      "source": [
        "!pip install -qU transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ecXT0l54JXUg"
      },
      "outputs": [],
      "source": [
        "# https://github.com/googlecolab/colabtools/issues/3409\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "twiYt3FtJCnR"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate bitsandbytes -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u72hdXUqRHVP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "# needs just under 16GB when using half precision, 8GB with 8Bit\n",
        "# might need more memory when generating responses\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "u9ybhzgXcAJh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "siaKgr-xRNHQ"
      },
      "outputs": [],
      "source": [
        "# compute_dtype = getattr(torch, \"float16\")\n",
        "# from transformers import BitsAndBytesConfig\n",
        "\n",
        "# bnb4_config = BitsAndBytesConfig(\n",
        "#         load_in_4bit=True,\n",
        "#         bnb_4bit_quant_type=\"nf4\",\n",
        "#         bnb_4bit_compute_dtype=compute_dtype,\n",
        "#         bnb_4bit_use_double_quant=True,\n",
        "# )\n",
        "# bnb8_config = BitsAndBytesConfig(\n",
        "#         load_in_8bit=True,\n",
        "#         bnb_8bit_quant_type=\"nf4\",\n",
        "#         bnb_8bit_compute_dtype=compute_dtype,\n",
        "#         bnb_8bit_use_double_quant=True,\n",
        "# )\n",
        "# bnb_config = bnb4_config\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bda5bb12191d43018177ddba91e64191",
            "3e4c7d267a224f6b8f0732d01e1a15ef",
            "7587e4931f354d2fbccde2aacbaab6d0",
            "aaf8d930940646c7afbdbf9867406183",
            "e89112da13eb494e8e0915d79272c8f4",
            "0c9c6d99773f476482de2fd68d66a60c",
            "8c9509f682be456abe0fe0a8fd87896e",
            "b83f7dcdb7ba4160bb0aaa53f7c4e12f",
            "eef98fca32ce4fc1990a97899ebe80cd",
            "722418079c78486086af1ca72a7ac1c3",
            "24282eba941b45e3a1c076886c4caad7"
          ]
        },
        "id": "y82ThhUTNKKa",
        "outputId": "d1de3460-4334-44ed-bcd0-a56a3830c528"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bda5bb12191d43018177ddba91e64191"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIek9xpaWmcO",
        "outputId": "75a5ab07-2525-4ea1-b7b8-40811c65519d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralAttention(\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): MistralRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm()\n",
              "        (post_attention_layernorm): MistralRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hallo, was ist die beste deutsche Krankenversicherung?\"},\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "U1nsltT7gB1V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "model_inputs = encodeds.to(device)\n",
        "\n",
        "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjozZYDWgN_F",
        "outputId": "ae718c14-6734-413f-9967-c311390a3ad0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST] Hallo, was ist die beste deutsche Krankenversicherung? [/INST] Hallo! Ich muss bescheiden sein und sage, dass ich keine absolute Antwort geben kann, die besten Deutschen Krankenversicherungen Abhängigkeiten von individuellen Bedürfnissen und Situationen sind. Es gibt verschiedene Krankenversicherungen in Deutschland, und jede bietet ihr eigenes Leistungsangebot und Preismodell.\n",
            "\n",
            "Aus einer allgemeinen Sicht kann man folgende Krankenversicherungen in Deutschland nennen, die für ihre Qualität und Service bekannt sind:\n",
            "\n",
            "1. Techniker Krankenkasse (TK)\n",
            "2. Barmer GEK\n",
            "3. AOK (Allgemeine Ortskrankenkasse)\n",
            "4. DAK (Deutsche Angestellten-Krankenkasse)\n",
            "5. BKK (Betriebskrankenkasse)\n",
            "\n",
            "Das Beste für Sie hängt von Ihren persönlichen Bedürfnissen und Kriterien ab, wie z.B. der Preis, die angebotenen Leistungen, und das Netzwerk der Doktoren und Krankenhäuser in Ihrer Region. Es ist always Empfehlenswert, Ihre Optionen verwissen und eine Umfrage oder Ratung mit einem unabhängigen Berater in Anspruch nehmen, um die besten passenden Krankenversicherung für Sie zu finden.\n",
            "\n",
            "Wenn Sie weitere Informationen oder Hilfe benötigen, freue ich mich darauf Ihre weitere Frage zu beantworten. 😊</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1u6DVhKHVAiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72223c51-67bc-4585-c54a-198978dcf2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 16 12:07:02 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              49W / 400W |  15253MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nST_gPVrcX0g"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPd3eE7XnyCA8qdOMVD0tud",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bda5bb12191d43018177ddba91e64191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e4c7d267a224f6b8f0732d01e1a15ef",
              "IPY_MODEL_7587e4931f354d2fbccde2aacbaab6d0",
              "IPY_MODEL_aaf8d930940646c7afbdbf9867406183"
            ],
            "layout": "IPY_MODEL_e89112da13eb494e8e0915d79272c8f4"
          }
        },
        "3e4c7d267a224f6b8f0732d01e1a15ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9c6d99773f476482de2fd68d66a60c",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9509f682be456abe0fe0a8fd87896e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7587e4931f354d2fbccde2aacbaab6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83f7dcdb7ba4160bb0aaa53f7c4e12f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eef98fca32ce4fc1990a97899ebe80cd",
            "value": 3
          }
        },
        "aaf8d930940646c7afbdbf9867406183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722418079c78486086af1ca72a7ac1c3",
            "placeholder": "​",
            "style": "IPY_MODEL_24282eba941b45e3a1c076886c4caad7",
            "value": " 3/3 [00:03&lt;00:00,  1.26s/it]"
          }
        },
        "e89112da13eb494e8e0915d79272c8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9c6d99773f476482de2fd68d66a60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9509f682be456abe0fe0a8fd87896e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83f7dcdb7ba4160bb0aaa53f7c4e12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef98fca32ce4fc1990a97899ebe80cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "722418079c78486086af1ca72a7ac1c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24282eba941b45e3a1c076886c4caad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}